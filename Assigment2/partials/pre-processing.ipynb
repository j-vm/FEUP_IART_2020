{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Machine Learning\n",
    "## FEUP MIEIC - InteligÃªncia Artificial *(EIC0029/IART)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing partial notebook\n",
    "\n",
    "This Jupyter Notebook implpementes and documents our approach to extract, maipulate, and in essence pre-process the data that will be used to train and test our machine learning models. <br><br>\n",
    "*The content of this notebook will be also included in the complete notebook named **IART-MachineLearning.ipynb** that can be found in the root directory of this repository*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to database\n",
    "database = \"database.sqlite\"\n",
    "con = sqlite3.connect(database)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * from MATCH': no such table: MATCH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\macj2\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1586\u001b[1;33m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1587\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: MATCH",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3380b1252123>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Get important tables from db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmatches_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"SELECT * from MATCH\"\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mteams_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"SELECT * from TEAM\"\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplayer_attributes_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"SELECT * from PLAYER_ATTRIBUTES\"\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mteam_attributes_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"SELECT * from TEAM_ATTRIBUTES\"\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\macj2\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         )\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\macj2\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m         \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1634\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\macj2\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m             \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * from MATCH': no such table: MATCH"
     ]
    }
   ],
   "source": [
    "#Get important tables from db\n",
    "matches_df = pd.read_sql(\"\"\"SELECT * from MATCH\"\"\", con)\n",
    "teams_df = pd.read_sql(\"\"\"SELECT * from TEAM\"\"\", con)\n",
    "player_attributes_df = pd.read_sql(\"\"\"SELECT * from PLAYER_ATTRIBUTES\"\"\", con)\n",
    "team_attributes_df = pd.read_sql(\"\"\"SELECT * from TEAM_ATTRIBUTES\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get players' attributes (overall)\n",
    "\n",
    "#Get players info\n",
    "home_players = [\"home_player_\" + str(x) for x in range(1, 12)]\n",
    "away_players = [\"away_player_\" + str(x) for x in range(1, 12)]\n",
    "\n",
    "matches_kept_columns = [\"id\", \"league_id\", \"date\", \"home_team_api_id\", \"away_team_api_id\", \"home_team_goal\", \"away_team_goal\"]\n",
    "matches_kept_columns = matches_kept_columns + home_players\n",
    "matches_kept_columns = matches_kept_columns + away_players\n",
    "\n",
    "matches_df = matches_df[matches_kept_columns]\n",
    "\n",
    "#Get overall ratings for all players from player_attributes table\n",
    "for player in home_players:\n",
    "    matches_df = pd.merge(matches_df, player_attributes_df[[\"id\", \"overall_rating\"]], left_on=[player], right_on=[\"id\"], suffixes=[\"\", \"_\" + player])\n",
    "for player in away_players:\n",
    "    matches_df = pd.merge(matches_df, player_attributes_df[[\"id\", \"overall_rating\"]], left_on=[player], right_on=[\"id\"], suffixes=[\"\", \"_\" + player])\n",
    " \n",
    "\n",
    "matches_df = matches_df.rename(columns={\"overall_rating\": \"overall_rating_home_player_1\"})\n",
    "\n",
    "matches_df['overall_rating_home'] = matches_df[['overall_rating_' + p for p in home_players]].sum(axis=1)\n",
    "matches_df['overall_rating_away'] = matches_df[['overall_rating_' + p for p in away_players]].sum(axis=1)\n",
    "matches_df['overall_rating_difference'] = matches_df['overall_rating_home'] - matches_df['overall_rating_away']\n",
    "\n",
    "matches_df['mean_overall_rating_home'] = matches_df[['overall_rating_' + p for p in home_players]].mean(axis=1)\n",
    "matches_df['mean_overall_rating_away'] = matches_df[['overall_rating_' + p for p in away_players]].mean(axis=1)\n",
    "\n",
    "\n",
    "#Remove all players column because we just need the \"global\" ones\n",
    "for c in matches_df.columns:\n",
    "    if '_player_' in c:\n",
    "        matches_df = matches_df.drop(c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate last 5 games performance\n",
    "#!!!!!!!!!!!!!TAKES ABOUT 5 MINUTES!!!!!!!!!! HAVE TO LOOK FOR ANOTHER WAY\n",
    "def last5(team_id, date, match_t):\n",
    "     \n",
    "    mat = match_t[(match_t['date'] < date)]\n",
    "    mat = mat[mat['home_team_api_id'] == team_id]\n",
    "    mat.sort_values(by=['date'], inplace=True, ascending=False) \n",
    "    #if there isn't 5 games...\n",
    "    mat5 = mat.head(5)\n",
    "    mat5['Home result'] = 0\n",
    "    mat5['Home result'] = np.where(mat5['home_team_goal'] > mat5['away_team_goal'], 3, mat5['Home result'])\n",
    "    mat5['Home result'] = np.where(mat5['home_team_goal'] == mat5['away_team_goal'], 1, mat5['Home result'])\n",
    "    total = mat5['Home result'].sum()\n",
    "    return total\n",
    "\n",
    "#match_t = pd.read_sql_query(\"select home_team_api_id, date, home_team_goal, away_team_goal from Match\",con)\n",
    "#match_t['date'] = pd.to_datetime(match_t['date'])\n",
    "#matches_df['Home_last5'] = 0\n",
    "#matches_df['Away_last5'] = 0\n",
    "#for i in matches_df.index:\n",
    "#    Htotal = last5(matches_df['home_team_api_id'].iloc[i], matches_df['date'].iloc[i], match_t)\n",
    "#    Atotal = last5(matches_df['away_team_api_id'].iloc[i], matches_df['date'].iloc[i], match_t)\n",
    "#    matches_df['Home_last5'].values[i] = Htotal\n",
    "#    matches_df['Away_last5'].values[i] = Atotal\n",
    "#    if i % 1000 == 0:\n",
    "#        print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_aux = pd.read_sql(\"\"\"SELECT * FROM MATCH\"\"\" ,con)\n",
    "\n",
    "#Select all bet columns (removed PSA, PSH, PSD because they are almost all NaN)\n",
    "bet_columns = [\"B365H\", \"B365A\", \"B365D\", \"BWH\", \"BWD\", \"BWA\", \"IWH\", \"IWD\", \"IWA\", \"LBH\", \"LBD\", \"LBA\", \"WHH\", \"WHD\", \"WHA\", \"SJH\", \"SJD\", \"SJA\", \"VCH\", \"VCD\", \"VCA\", \"GBH\", \"GBD\", \"GBA\", \"BSH\", \"BSD\", \"BSA\"]\n",
    "\n",
    "#Get specific columns for bets on home and draw\n",
    "bet_columns_home = [\"B365H\", \"BWH\",\"IWH\", \"LBH\", \"WHH\", \"SJH\", \"VCH\", \"GBH\",\"BSH\"]\n",
    "bet_columns_draw = [\"B365D\", \"BWD\",\"IWD\", \"LBD\", \"WHD\", \"SJD\", \"VCD\", \"GBD\",\"BSD\"]\n",
    "\n",
    "#Calculate mean values for bets on home team and draw. Add these values to match table\n",
    "matches_df['mean_bets_home'] = matches_aux[bet_columns_home].mean(axis=1)\n",
    "matches_df['mean_bets_draw'] = matches_aux[bet_columns_draw].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN values (on bets) with mean values \n",
    "matches_df.fillna(matches_df.mean(), inplace=True)\n",
    "matches_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get goal difference\n",
    "matches_df['goal_diff'] = matches_df['home_team_goal'] - matches_df['away_team_goal']\n",
    "\n",
    "matches_df['Game Result'] = 'Defeat'\n",
    "matches_df['Game Result'] = np.where(matches_df['goal_diff'] == 0, 'Draw', matches_df['Game Result'])\n",
    "matches_df['Game Result'] = np.where(matches_df['goal_diff'] > 0, 'Win', matches_df['Game Result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = sns.FacetGrid(matches_df, col=\"goal_diff\", hue=\"league_id\")\n",
    "h.map(plt.scatter, \"overall_rating_home\", \"overall_rating_away\", alpha=.7)\n",
    "h.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matches_df = matches_df.drop([ 'id', 'league_id', 'date', 'home_team_api_id','away_team_api_id','home_team_goal','away_team_goal','overall_rating_home', 'overall_rating_away', 'overall_rating_difference', 'goal_diff'], axis=1)\n",
    "sns.pairplot(matches_df, hue='Game Result')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = matches_df['Game Result']\n",
    "X = matches_df.drop('Game Result', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train set selection\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
